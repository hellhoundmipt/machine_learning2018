{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import jsonlines\n",
    "from os import listdir\n",
    "import itertools\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import pymorphy2 as pm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_set = set()\n",
    "with open(\"sources/accepted_categories.txt\", mode=\"r\", encoding=\"utf-8\") as inp:\n",
    "    for line in inp:\n",
    "        line = line[:-1]\n",
    "        ok_set.add(line)\n",
    "\n",
    "ok = sorted(ok_set)\n",
    "\n",
    "categories_dict = {}\n",
    "with open(\"sources/article_cat.json\", mode=\"r\") as input:\n",
    "    categories_dict = json.loads(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted([item['id'] for item in jsonlines.open('sources/normalized_texts.jl', 'r')])\n",
    "X = load_npz(\"sources/tf_idf.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96790 96792 96793] TEST: [    3     4     7 ... 96785 96789 96791]\n",
      "64529 32265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                        | 0/14697 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Maxim\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Maxim\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14697/14697 [3:36:13<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=27)\n",
    "\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in kf.split(X):\n",
    "    train_index, test_index = item[0], item[1]\n",
    "    break\n",
    "    \n",
    "print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "print(len(train_index), len(test_index))\n",
    "    \n",
    "X_train = X#[train_index]\n",
    "ids_train = ids#[ids[i] for i in train_index]\n",
    "\n",
    "class_centroids = []\n",
    "skipped_categories = []\n",
    "\n",
    "for i, category in enumerate(tqdm(ok)):\n",
    "    clf_centroids = NearestCentroid()\n",
    "    y_train = np.array([1 if category in categories_dict[id] else 0 for id in ids_train])\n",
    "    if sum(y_train) > 0:\n",
    "        clf_centroids.fit(X_train, y_train)\n",
    "        class_centroids.append(csr_matrix(clf_centroids.centroids_[1]))\n",
    "    else:\n",
    "        skipped_categories.append(ok[i])\n",
    "        print(category)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124767"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_centroids[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class_centroids = lil_matrix((len(class_centroids), class_centroids[0].shape[1]))\n",
    "for i in range(len(class_centroids)):\n",
    "    _class_centroids[i] = class_centroids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"sources/centroids_tfidf\", _class_centroids.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
