{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import jsonlines\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm\n",
    "import networkx as nx\n",
    "import re\n",
    "from bisect import bisect_left\n",
    "#from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from random import shuffle\n",
    "from sys import exit\n",
    "import numpy as np\n",
    "import json\n",
    "import codecs\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_set = set()\n",
    "with open(\"sources/accepted_categories.txt\", mode=\"r\", encoding=\"utf-8\") as inp:\n",
    "    for line in inp:\n",
    "        line = line[:-1]\n",
    "        ok_set.add(line)\n",
    "\n",
    "ok = sorted(ok_set)\n",
    "\n",
    "categories_dict = {}\n",
    "with open(\"sources/article_cat.json\", mode=\"r\") as input:\n",
    "    categories_dict = json.loads(input.read())\n",
    "\n",
    "#X = load_npz(\"sources/tf_idf.npz\")\n",
    "#class_centroids = load_npz(\"sources/centroids_titles_bigrams.npz\")\n",
    "#X_titles = load_npz(\"sources/X_titles_bigrams.npz\")\n",
    "\n",
    "X = np.load(\"sources/svd500.npy\").astype(np.float16)\n",
    "class_centroids = np.load(\"sources/centroids_svd500.npy\").astype(np.float16)\n",
    "X_titles = X\n",
    "    \n",
    "ids = sorted([item['id'] for item in jsonlines.open('sources/normalized_texts.jl', 'r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14697, 500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96794, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest = 5\n",
    "\n",
    "kn_clust = NearestNeighbors(n_neighbors=k_nearest)\n",
    "kn_clust.fit(class_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96794it [00:04, 23128.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [08:14<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "#for sparce features\n",
    "X_left = []\n",
    "for x in tqdm(X):\n",
    "    for j in range(k_nearest):\n",
    "        X_left.append(x)       \n",
    "X_left = vstack(X_left)\n",
    "\n",
    "X_right = []\n",
    "y = []\n",
    "rows = []\n",
    "batchsize = 1000\n",
    "for i in trange(0, X.shape[0], batchsize):\n",
    "    curr_x = X[i:i+batchsize]\n",
    "    _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "    \n",
    "    for j, neighbors in enumerate(_neighbors):\n",
    "        cats = categories_dict[ids[i+j]]\n",
    "        neighbors = [ok[c] for c in neighbors]\n",
    "        common = set(neighbors).intersection(set(cats))\n",
    "        for neigh in neighbors:\n",
    "            rows.append(ok.index(neigh))\n",
    "            y.append(1 if neigh in common else 0)\n",
    "\n",
    "X_right = class_centroids[rows]\n",
    "X_full = hstack([X_left, X_right])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 96794/96794 [00:00<00:00, 545289.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [24:21<00:00, 15.07s/it]\n"
     ]
    }
   ],
   "source": [
    "#for dence features\n",
    "X_left = []\n",
    "for x in tqdm(X):\n",
    "    for j in range(k_nearest):\n",
    "        X_left.append(x)       \n",
    "X_left = np.array(X_left)\n",
    "\n",
    "X_right = []\n",
    "y = []\n",
    "rows = []\n",
    "batchsize = 1000\n",
    "for i in trange(0, X.shape[0], batchsize):\n",
    "    curr_x = X[i:i+batchsize]\n",
    "    _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "    \n",
    "    for j, neighbors in enumerate(_neighbors):\n",
    "        cats = categories_dict[ids[i+j]]\n",
    "        neighbors = [ok[c] for c in neighbors]\n",
    "        common = set(neighbors).intersection(set(cats))\n",
    "        for neigh in neighbors:\n",
    "            rows.append(ok.index(neigh))\n",
    "            y.append(1 if neigh in common else 0)\n",
    "\n",
    "X_right = class_centroids[rows]\n",
    "X_full = np.concatenate((X_left, X_right), axis=1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96794it [00:04, 21649.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [01:39<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "#when X and class_centroids have different shape[1] (tf-idf + titles)\n",
    "X_left = []\n",
    "for x in tqdm(X):\n",
    "    for j in range(k_nearest):\n",
    "        X_left.append(x)       \n",
    "X_left = vstack(X_left)\n",
    "\n",
    "X_right = []\n",
    "y = []\n",
    "rows = []\n",
    "batchsize = 1000\n",
    "for i in trange(0, X.shape[0], batchsize):\n",
    "    curr_x = X_titles[i:i+batchsize]\n",
    "    _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "    \n",
    "    for j, neighbors in enumerate(_neighbors):\n",
    "        cats = categories_dict[ids[i+j]]\n",
    "        neighbors = [ok[c] for c in neighbors]\n",
    "        common = set(neighbors).intersection(set(cats))\n",
    "        for neigh in neighbors:\n",
    "            rows.append(ok.index(neigh))\n",
    "            y.append(1 if neigh in common else 0)\n",
    "\n",
    "X_right = class_centroids[rows]\n",
    "X_full = hstack([X_left, X_right])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118137 483970\n"
     ]
    }
   ],
   "source": [
    "print(sum(y), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1\n",
      "{'fit_time': array([91.27764368, 94.64258122, 78.35975432]), 'score_time': array([1.8619504 , 1.76569438, 1.70653677]), 'test_accu': array([0.5699214 , 0.549872  , 0.69366426]), 'train_accu': array([0.6377206 , 0.65372993, 0.61591461])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1.0\n",
      "{'fit_time': array([231.68989396, 205.8109622 , 163.73263597]), 'score_time': array([1.92160892, 1.72458482, 2.08755064]), 'test_accu': array([0.56837172, 0.55315113, 0.68884784]), 'train_accu': array([0.64902711, 0.66385554, 0.61458808])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 5\n",
      "{'fit_time': array([375.29845953, 371.31261945, 342.52797055]), 'score_time': array([1.81383038, 1.77070642, 1.80981112]), 'test_accu': array([0.56768367, 0.55266763, 0.68776306]), 'train_accu': array([0.65136093, 0.66589802, 0.61371406])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 10\n",
      "{'fit_time': array([436.94964576, 428.39220166, 425.00939941]), 'score_time': array([1.72659039, 1.8078053 , 1.69751263]), 'test_accu': array([0.56741092, 0.55258085, 0.68791803]), 'train_accu': array([0.65155929, 0.6660251 , 0.61310348])}\n"
     ]
    }
   ],
   "source": [
    "for c in [0.1, 1.0, 5, 10, 20]:\n",
    "    clf = LogisticRegression(C=c, class_weight=\"balanced\")\n",
    "    scoring = {'accu': 'accuracy'}\n",
    "    scores = cross_validate(clf, X_full, y, cv=3, return_train_score=True, scoring=scoring)\n",
    "    print(\"C = \" + str(c))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96790 96792 96793] TEST: [    3     4     7 ... 96785 96789 96791]\n",
      "64529 32265\n",
      "TRAIN: [    2     3     4 ... 96791 96792 96793] TEST: [    0     1     5 ... 96787 96788 96790]\n",
      "64529 32265\n",
      "TRAIN: [    0     1     3 ... 96789 96790 96791] TEST: [    2     6     9 ... 96786 96792 96793]\n",
      "64530 32264\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "n_splits = 3\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=27)\n",
    "X_full = X_full.tocsr()\n",
    "for item in kf.split(ids):\n",
    "    train_index, test_index = item[0], item[1]\n",
    "    \n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "    clf = LogisticRegression(C=10, class_weight=\"balanced\")\n",
    "    clf.fit(X_full[train_index], y[train_index])\n",
    "    joblib.dump(clf, \"sources/binlogreg_clfs/binlogreg_tfidf_titlesbigrams\" + str(i) +\".pkl\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483970, 130597)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
